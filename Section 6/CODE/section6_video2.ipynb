{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tuner\n",
    "This notebook walks through how to use the Keras tuner. First you need to make sure it is installed in your environment by using `pip install keras-tuner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the MNIST dataset for demonstrating how to perform autotuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x, y), (val_x, val_y) = keras.datasets.mnist.load_data()\n",
    "x = x.astype('float32') / 255.\n",
    "val_x = val_x.astype('float32') / 255.\n",
    "\n",
    "#let's grab the first 10000\n",
    "x = x[:10000]\n",
    "y = y[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a model architecture. Notice we are passing in a parameter which takes the hyperparameter tuner. With this, we can then sample things such as integers or even learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hyperparameters):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "    model.add(layers.Dense(units=hyperparameters.Int('units',min_value=32,max_value=512,step=32),activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hyperparameters.Choice('learning_rate',values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify a tuner. There are 2 types currently available: RandomSearch or Hyperband with Keras Tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='.',\n",
    "    project_name='keras_tuner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run training on your model using the tuner. This will run model.fit but search for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      " 9952/10000 [============================>.] - ETA: 31s - loss: 2.3833 - acc: 0.12 - ETA: 5s - loss: 2.3393 - acc: 0.1354 - ETA: 8s - loss: 2.3095 - acc: 0.159 - ETA: 4s - loss: 2.2478 - acc: 0.204 - ETA: 3s - loss: 2.1526 - acc: 0.309 - ETA: 2s - loss: 2.0984 - acc: 0.346 - ETA: 2s - loss: 2.0477 - acc: 0.384 - ETA: 1s - loss: 1.9410 - acc: 0.452 - ETA: 1s - loss: 1.8612 - acc: 0.494 - ETA: 1s - loss: 1.8086 - acc: 0.514 - ETA: 1s - loss: 1.7526 - acc: 0.537 - ETA: 1s - loss: 1.7203 - acc: 0.550 - ETA: 1s - loss: 1.6893 - acc: 0.562 - ETA: 1s - loss: 1.6306 - acc: 0.585 - ETA: 1s - loss: 1.5684 - acc: 0.606 - ETA: 0s - loss: 1.5067 - acc: 0.625 - ETA: 0s - loss: 1.4877 - acc: 0.631 - ETA: 0s - loss: 1.4172 - acc: 0.652 - ETA: 0s - loss: 1.4117 - acc: 0.654 - ETA: 0s - loss: 1.3563 - acc: 0.670 - ETA: 0s - loss: 1.3330 - acc: 0.676 - ETA: 0s - loss: 1.2847 - acc: 0.6909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:12.507874 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 325us/sample - loss: 1.2820 - acc: 0.6918 - val_loss: 0.7022 - val_acc: 0.8499\n",
      "Epoch 2/5\n",
      " 9984/10000 [============================>.] - ETA: 1s - loss: 0.6916 - acc: 0.812 - ETA: 0s - loss: 0.6651 - acc: 0.858 - ETA: 2s - loss: 0.6622 - acc: 0.858 - ETA: 1s - loss: 0.6581 - acc: 0.855 - ETA: 1s - loss: 0.6595 - acc: 0.857 - ETA: 2s - loss: 0.6582 - acc: 0.859 - ETA: 1s - loss: 0.6429 - acc: 0.858 - ETA: 1s - loss: 0.6388 - acc: 0.859 - ETA: 1s - loss: 0.6313 - acc: 0.863 - ETA: 1s - loss: 0.6272 - acc: 0.865 - ETA: 1s - loss: 0.6152 - acc: 0.869 - ETA: 1s - loss: 0.6104 - acc: 0.870 - ETA: 1s - loss: 0.6073 - acc: 0.870 - ETA: 1s - loss: 0.6031 - acc: 0.870 - ETA: 1s - loss: 0.5979 - acc: 0.870 - ETA: 0s - loss: 0.5857 - acc: 0.873 - ETA: 0s - loss: 0.5819 - acc: 0.873 - ETA: 0s - loss: 0.5770 - acc: 0.873 - ETA: 0s - loss: 0.5723 - acc: 0.873 - ETA: 0s - loss: 0.5675 - acc: 0.873 - ETA: 0s - loss: 0.5606 - acc: 0.873 - ETA: 0s - loss: 0.5551 - acc: 0.874 - ETA: 0s - loss: 0.5509 - acc: 0.874 - ETA: 0s - loss: 0.5500 - acc: 0.8746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:14.784182 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.5496 - acc: 0.8748 - val_loss: 0.4630 - val_acc: 0.8897\n",
      "Epoch 3/5\n",
      " 9952/10000 [============================>.] - ETA: 1s - loss: 0.4670 - acc: 0.968 - ETA: 7s - loss: 0.4746 - acc: 0.919 - ETA: 2s - loss: 0.4644 - acc: 0.895 - ETA: 1s - loss: 0.4618 - acc: 0.895 - ETA: 2s - loss: 0.4594 - acc: 0.896 - ETA: 2s - loss: 0.4558 - acc: 0.897 - ETA: 2s - loss: 0.4608 - acc: 0.893 - ETA: 1s - loss: 0.4488 - acc: 0.893 - ETA: 1s - loss: 0.4478 - acc: 0.891 - ETA: 1s - loss: 0.4449 - acc: 0.891 - ETA: 1s - loss: 0.4415 - acc: 0.892 - ETA: 1s - loss: 0.4324 - acc: 0.894 - ETA: 0s - loss: 0.4269 - acc: 0.895 - ETA: 0s - loss: 0.4245 - acc: 0.896 - ETA: 0s - loss: 0.4214 - acc: 0.896 - ETA: 0s - loss: 0.4179 - acc: 0.897 - ETA: 0s - loss: 0.4185 - acc: 0.897 - ETA: 0s - loss: 0.4143 - acc: 0.897 - ETA: 0s - loss: 0.4134 - acc: 0.898 - ETA: 0s - loss: 0.4112 - acc: 0.898 - ETA: 0s - loss: 0.4097 - acc: 0.898 - ETA: 0s - loss: 0.4080 - acc: 0.900 - ETA: 0s - loss: 0.4064 - acc: 0.9007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:17.964890 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 317us/sample - loss: 0.4065 - acc: 0.9007 - val_loss: 0.3866 - val_acc: 0.8999\n",
      "Epoch 4/5\n",
      " 9696/10000 [============================>.] - ETA: 1s - loss: 0.5652 - acc: 0.812 - ETA: 7s - loss: 0.4409 - acc: 0.864 - ETA: 12s - loss: 0.3814 - acc: 0.90 - ETA: 3s - loss: 0.3639 - acc: 0.9062 - ETA: 3s - loss: 0.3881 - acc: 0.897 - ETA: 2s - loss: 0.3815 - acc: 0.903 - ETA: 2s - loss: 0.3696 - acc: 0.906 - ETA: 2s - loss: 0.3625 - acc: 0.908 - ETA: 2s - loss: 0.3628 - acc: 0.909 - ETA: 2s - loss: 0.3616 - acc: 0.910 - ETA: 1s - loss: 0.3568 - acc: 0.911 - ETA: 1s - loss: 0.3545 - acc: 0.912 - ETA: 1s - loss: 0.3494 - acc: 0.913 - ETA: 1s - loss: 0.3469 - acc: 0.914 - ETA: 1s - loss: 0.3480 - acc: 0.912 - ETA: 1s - loss: 0.3493 - acc: 0.912 - ETA: 1s - loss: 0.3481 - acc: 0.912 - ETA: 1s - loss: 0.3469 - acc: 0.912 - ETA: 1s - loss: 0.3460 - acc: 0.912 - ETA: 1s - loss: 0.3445 - acc: 0.914 - ETA: 1s - loss: 0.3447 - acc: 0.914 - ETA: 0s - loss: 0.3421 - acc: 0.914 - ETA: 0s - loss: 0.3420 - acc: 0.914 - ETA: 0s - loss: 0.3438 - acc: 0.913 - ETA: 0s - loss: 0.3450 - acc: 0.913 - ETA: 0s - loss: 0.3465 - acc: 0.9127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:21.498531 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 353us/sample - loss: 0.3451 - acc: 0.9132 - val_loss: 0.3442 - val_acc: 0.9107\n",
      "Epoch 5/5\n",
      " 9408/10000 [===========================>..] - ETA: 1s - loss: 0.2532 - acc: 0.937 - ETA: 9s - loss: 0.3386 - acc: 0.906 - ETA: 1s - loss: 0.3240 - acc: 0.907 - ETA: 1s - loss: 0.3197 - acc: 0.906 - ETA: 1s - loss: 0.3103 - acc: 0.912 - ETA: 1s - loss: 0.3035 - acc: 0.915 - ETA: 1s - loss: 0.3019 - acc: 0.915 - ETA: 1s - loss: 0.3019 - acc: 0.915 - ETA: 1s - loss: 0.3017 - acc: 0.916 - ETA: 1s - loss: 0.3010 - acc: 0.918 - ETA: 2s - loss: 0.3023 - acc: 0.918 - ETA: 1s - loss: 0.3052 - acc: 0.916 - ETA: 1s - loss: 0.3069 - acc: 0.915 - ETA: 1s - loss: 0.3038 - acc: 0.916 - ETA: 1s - loss: 0.3017 - acc: 0.917 - ETA: 1s - loss: 0.3012 - acc: 0.918 - ETA: 1s - loss: 0.3028 - acc: 0.918 - ETA: 1s - loss: 0.3027 - acc: 0.919 - ETA: 0s - loss: 0.3063 - acc: 0.917 - ETA: 0s - loss: 0.3077 - acc: 0.917 - ETA: 0s - loss: 0.3073 - acc: 0.918 - ETA: 0s - loss: 0.3082 - acc: 0.918 - ETA: 0s - loss: 0.3079 - acc: 0.919 - ETA: 0s - loss: 0.3098 - acc: 0.918 - ETA: 0s - loss: 0.3093 - acc: 0.9188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:24.845237 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 334us/sample - loss: 0.3073 - acc: 0.9189 - val_loss: 0.3194 - val_acc: 0.9152\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      " 9632/10000 [===========================>..] - ETA: 26s - loss: 2.2546 - acc: 0.12 - ETA: 9s - loss: 2.2517 - acc: 0.1406 - ETA: 5s - loss: 2.2178 - acc: 0.177 - ETA: 5s - loss: 2.1689 - acc: 0.215 - ETA: 3s - loss: 2.0681 - acc: 0.326 - ETA: 3s - loss: 2.0261 - acc: 0.364 - ETA: 2s - loss: 1.9925 - acc: 0.391 - ETA: 2s - loss: 1.8733 - acc: 0.477 - ETA: 1s - loss: 1.7669 - acc: 0.528 - ETA: 1s - loss: 1.7216 - acc: 0.550 - ETA: 1s - loss: 1.7175 - acc: 0.551 - ETA: 1s - loss: 1.6432 - acc: 0.580 - ETA: 1s - loss: 1.6176 - acc: 0.589 - ETA: 1s - loss: 1.5366 - acc: 0.618 - ETA: 0s - loss: 1.4823 - acc: 0.637 - ETA: 0s - loss: 1.4324 - acc: 0.653 - ETA: 0s - loss: 1.3959 - acc: 0.664 - ETA: 0s - loss: 1.3567 - acc: 0.675 - ETA: 0s - loss: 1.3215 - acc: 0.685 - ETA: 0s - loss: 1.2851 - acc: 0.693 - ETA: 0s - loss: 1.2508 - acc: 0.7029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:28.024733 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 277us/sample - loss: 1.2307 - acc: 0.7073 - val_loss: 0.6721 - val_acc: 0.8560\n",
      "Epoch 2/5\n",
      " 9984/10000 [============================>.] - ETA: 0s - loss: 0.5593 - acc: 0.875 - ETA: 0s - loss: 0.6616 - acc: 0.848 - ETA: 1s - loss: 0.6419 - acc: 0.863 - ETA: 1s - loss: 0.6263 - acc: 0.861 - ETA: 1s - loss: 0.6278 - acc: 0.862 - ETA: 1s - loss: 0.6178 - acc: 0.862 - ETA: 1s - loss: 0.6014 - acc: 0.865 - ETA: 0s - loss: 0.6001 - acc: 0.863 - ETA: 0s - loss: 0.5921 - acc: 0.865 - ETA: 0s - loss: 0.5885 - acc: 0.866 - ETA: 0s - loss: 0.5819 - acc: 0.866 - ETA: 0s - loss: 0.5764 - acc: 0.867 - ETA: 0s - loss: 0.5643 - acc: 0.871 - ETA: 0s - loss: 0.5503 - acc: 0.874 - ETA: 0s - loss: 0.5430 - acc: 0.874 - ETA: 0s - loss: 0.5433 - acc: 0.874 - ETA: 0s - loss: 0.5367 - acc: 0.874 - ETA: 0s - loss: 0.5297 - acc: 0.8759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:30.065262 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.5300 - acc: 0.8757 - val_loss: 0.4554 - val_acc: 0.8868\n",
      "Epoch 3/5\n",
      " 9440/10000 [===========================>..] - ETA: 2s - loss: 0.4913 - acc: 0.906 - ETA: 0s - loss: 0.4426 - acc: 0.892 - ETA: 0s - loss: 0.4374 - acc: 0.890 - ETA: 0s - loss: 0.4306 - acc: 0.890 - ETA: 0s - loss: 0.4092 - acc: 0.897 - ETA: 0s - loss: 0.4057 - acc: 0.899 - ETA: 0s - loss: 0.4051 - acc: 0.900 - ETA: 0s - loss: 0.4036 - acc: 0.901 - ETA: 0s - loss: 0.4045 - acc: 0.900 - ETA: 0s - loss: 0.4043 - acc: 0.900 - ETA: 0s - loss: 0.4057 - acc: 0.899 - ETA: 0s - loss: 0.4018 - acc: 0.900 - ETA: 0s - loss: 0.3990 - acc: 0.900 - ETA: 0s - loss: 0.4013 - acc: 0.899 - ETA: 0s - loss: 0.4018 - acc: 0.899 - ETA: 0s - loss: 0.4003 - acc: 0.8995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:31.811321 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 174us/sample - loss: 0.3977 - acc: 0.9001 - val_loss: 0.3830 - val_acc: 0.9010\n",
      "Epoch 4/5\n",
      " 9440/10000 [===========================>..] - ETA: 9s - loss: 0.4078 - acc: 0.875 - ETA: 0s - loss: 0.3577 - acc: 0.906 - ETA: 1s - loss: 0.3579 - acc: 0.907 - ETA: 1s - loss: 0.3577 - acc: 0.906 - ETA: 2s - loss: 0.3573 - acc: 0.905 - ETA: 1s - loss: 0.3610 - acc: 0.907 - ETA: 1s - loss: 0.3579 - acc: 0.905 - ETA: 1s - loss: 0.3573 - acc: 0.905 - ETA: 1s - loss: 0.3536 - acc: 0.907 - ETA: 1s - loss: 0.3550 - acc: 0.906 - ETA: 1s - loss: 0.3528 - acc: 0.906 - ETA: 1s - loss: 0.3544 - acc: 0.907 - ETA: 0s - loss: 0.3544 - acc: 0.908 - ETA: 0s - loss: 0.3516 - acc: 0.909 - ETA: 0s - loss: 0.3522 - acc: 0.909 - ETA: 0s - loss: 0.3528 - acc: 0.909 - ETA: 0s - loss: 0.3497 - acc: 0.910 - ETA: 0s - loss: 0.3491 - acc: 0.910 - ETA: 0s - loss: 0.3473 - acc: 0.910 - ETA: 0s - loss: 0.3455 - acc: 0.911 - ETA: 0s - loss: 0.3420 - acc: 0.912 - ETA: 0s - loss: 0.3412 - acc: 0.9119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:34.351993 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.3402 - acc: 0.9125 - val_loss: 0.3434 - val_acc: 0.9080\n",
      "Epoch 5/5\n",
      " 9824/10000 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.875 - ETA: 6s - loss: 0.3362 - acc: 0.910 - ETA: 2s - loss: 0.3029 - acc: 0.919 - ETA: 3s - loss: 0.2986 - acc: 0.920 - ETA: 2s - loss: 0.3084 - acc: 0.920 - ETA: 2s - loss: 0.3048 - acc: 0.921 - ETA: 1s - loss: 0.3020 - acc: 0.924 - ETA: 1s - loss: 0.2985 - acc: 0.925 - ETA: 1s - loss: 0.2971 - acc: 0.926 - ETA: 1s - loss: 0.3059 - acc: 0.924 - ETA: 1s - loss: 0.3069 - acc: 0.922 - ETA: 1s - loss: 0.3092 - acc: 0.921 - ETA: 0s - loss: 0.3061 - acc: 0.922 - ETA: 0s - loss: 0.3039 - acc: 0.922 - ETA: 0s - loss: 0.3042 - acc: 0.922 - ETA: 0s - loss: 0.3019 - acc: 0.922 - ETA: 0s - loss: 0.3039 - acc: 0.922 - ETA: 0s - loss: 0.3059 - acc: 0.921 - ETA: 0s - loss: 0.3058 - acc: 0.921 - ETA: 0s - loss: 0.3033 - acc: 0.922 - ETA: 0s - loss: 0.3037 - acc: 0.922 - ETA: 0s - loss: 0.3035 - acc: 0.922 - ETA: 0s - loss: 0.3037 - acc: 0.9219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:37.294003 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 294us/sample - loss: 0.3039 - acc: 0.9217 - val_loss: 0.3203 - val_acc: 0.9131\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      " 9664/10000 [===========================>..] - ETA: 25s - loss: 2.3497 - acc: 0.12 - ETA: 2s - loss: 2.3128 - acc: 0.1094 - ETA: 5s - loss: 2.3085 - acc: 0.114 - ETA: 2s - loss: 2.1921 - acc: 0.212 - ETA: 1s - loss: 2.0976 - acc: 0.303 - ETA: 1s - loss: 2.0231 - acc: 0.368 - ETA: 1s - loss: 1.9532 - acc: 0.421 - ETA: 1s - loss: 1.9392 - acc: 0.433 - ETA: 1s - loss: 1.9041 - acc: 0.456 - ETA: 1s - loss: 1.8284 - acc: 0.502 - ETA: 1s - loss: 1.8037 - acc: 0.515 - ETA: 1s - loss: 1.7273 - acc: 0.552 - ETA: 1s - loss: 1.6942 - acc: 0.565 - ETA: 0s - loss: 1.6513 - acc: 0.583 - ETA: 1s - loss: 1.6453 - acc: 0.585 - ETA: 0s - loss: 1.6147 - acc: 0.595 - ETA: 0s - loss: 1.5570 - acc: 0.616 - ETA: 0s - loss: 1.5245 - acc: 0.627 - ETA: 0s - loss: 1.5042 - acc: 0.633 - ETA: 0s - loss: 1.4335 - acc: 0.654 - ETA: 0s - loss: 1.3918 - acc: 0.666 - ETA: 0s - loss: 1.3893 - acc: 0.667 - ETA: 0s - loss: 1.3503 - acc: 0.678 - ETA: 0s - loss: 1.3356 - acc: 0.682 - ETA: 0s - loss: 1.3315 - acc: 0.6829"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:40.897691 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 322us/sample - loss: 1.3118 - acc: 0.6880 - val_loss: 0.7108 - val_acc: 0.8499\n",
      "Epoch 2/5\n",
      " 9504/10000 [===========================>..] - ETA: 1s - loss: 0.5388 - acc: 0.906 - ETA: 3s - loss: 0.7061 - acc: 0.849 - ETA: 1s - loss: 0.6915 - acc: 0.854 - ETA: 2s - loss: 0.6788 - acc: 0.860 - ETA: 1s - loss: 0.6488 - acc: 0.867 - ETA: 1s - loss: 0.6451 - acc: 0.863 - ETA: 1s - loss: 0.6300 - acc: 0.866 - ETA: 1s - loss: 0.6206 - acc: 0.866 - ETA: 0s - loss: 0.6118 - acc: 0.867 - ETA: 0s - loss: 0.6080 - acc: 0.867 - ETA: 0s - loss: 0.6026 - acc: 0.869 - ETA: 0s - loss: 0.5834 - acc: 0.873 - ETA: 0s - loss: 0.5805 - acc: 0.873 - ETA: 0s - loss: 0.5739 - acc: 0.873 - ETA: 0s - loss: 0.5725 - acc: 0.872 - ETA: 0s - loss: 0.5643 - acc: 0.8731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:42.980905 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 208us/sample - loss: 0.5584 - acc: 0.8749 - val_loss: 0.4683 - val_acc: 0.8857\n",
      "Epoch 3/5\n",
      " 9760/10000 [============================>.] - ETA: 1s - loss: 0.7584 - acc: 0.750 - ETA: 2s - loss: 0.4727 - acc: 0.875 - ETA: 1s - loss: 0.4618 - acc: 0.882 - ETA: 0s - loss: 0.4546 - acc: 0.883 - ETA: 0s - loss: 0.4494 - acc: 0.885 - ETA: 0s - loss: 0.4347 - acc: 0.890 - ETA: 0s - loss: 0.4297 - acc: 0.892 - ETA: 0s - loss: 0.4259 - acc: 0.895 - ETA: 0s - loss: 0.4209 - acc: 0.896 - ETA: 0s - loss: 0.4181 - acc: 0.897 - ETA: 0s - loss: 0.4149 - acc: 0.897 - ETA: 0s - loss: 0.4139 - acc: 0.897 - ETA: 0s - loss: 0.4162 - acc: 0.896 - ETA: 0s - loss: 0.4163 - acc: 0.896 - ETA: 0s - loss: 0.4146 - acc: 0.897 - ETA: 0s - loss: 0.4144 - acc: 0.897 - ETA: 0s - loss: 0.4120 - acc: 0.8994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:44.843781 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 186us/sample - loss: 0.4135 - acc: 0.8986 - val_loss: 0.3917 - val_acc: 0.8989\n",
      "Epoch 4/5\n",
      " 9952/10000 [============================>.] - ETA: 1s - loss: 0.6256 - acc: 0.843 - ETA: 3s - loss: 0.3903 - acc: 0.888 - ETA: 5s - loss: 0.3999 - acc: 0.886 - ETA: 1s - loss: 0.3903 - acc: 0.889 - ETA: 2s - loss: 0.3942 - acc: 0.888 - ETA: 1s - loss: 0.3661 - acc: 0.902 - ETA: 1s - loss: 0.3782 - acc: 0.901 - ETA: 1s - loss: 0.3784 - acc: 0.900 - ETA: 1s - loss: 0.3730 - acc: 0.903 - ETA: 1s - loss: 0.3758 - acc: 0.901 - ETA: 1s - loss: 0.3731 - acc: 0.902 - ETA: 1s - loss: 0.3728 - acc: 0.901 - ETA: 1s - loss: 0.3723 - acc: 0.902 - ETA: 1s - loss: 0.3740 - acc: 0.902 - ETA: 0s - loss: 0.3728 - acc: 0.902 - ETA: 0s - loss: 0.3657 - acc: 0.904 - ETA: 0s - loss: 0.3638 - acc: 0.904 - ETA: 0s - loss: 0.3634 - acc: 0.904 - ETA: 0s - loss: 0.3590 - acc: 0.906 - ETA: 0s - loss: 0.3563 - acc: 0.908 - ETA: 0s - loss: 0.3549 - acc: 0.908 - ETA: 0s - loss: 0.3534 - acc: 0.909 - ETA: 0s - loss: 0.3520 - acc: 0.9105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:47.778179 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 293us/sample - loss: 0.3521 - acc: 0.9104 - val_loss: 0.3503 - val_acc: 0.9070\n",
      "Epoch 5/5\n",
      " 9696/10000 [============================>.] - ETA: 0s - loss: 0.3707 - acc: 0.875 - ETA: 21s - loss: 0.3494 - acc: 0.89 - ETA: 2s - loss: 0.3218 - acc: 0.9178 - ETA: 1s - loss: 0.3248 - acc: 0.922 - ETA: 1s - loss: 0.3267 - acc: 0.921 - ETA: 1s - loss: 0.3315 - acc: 0.921 - ETA: 1s - loss: 0.3366 - acc: 0.920 - ETA: 1s - loss: 0.3380 - acc: 0.917 - ETA: 1s - loss: 0.3352 - acc: 0.918 - ETA: 1s - loss: 0.3278 - acc: 0.919 - ETA: 1s - loss: 0.3261 - acc: 0.919 - ETA: 1s - loss: 0.3246 - acc: 0.919 - ETA: 1s - loss: 0.3236 - acc: 0.920 - ETA: 0s - loss: 0.3172 - acc: 0.921 - ETA: 0s - loss: 0.3162 - acc: 0.921 - ETA: 0s - loss: 0.3196 - acc: 0.920 - ETA: 0s - loss: 0.3183 - acc: 0.921 - ETA: 0s - loss: 0.3181 - acc: 0.921 - ETA: 0s - loss: 0.3183 - acc: 0.919 - ETA: 0s - loss: 0.3168 - acc: 0.919 - ETA: 0s - loss: 0.3147 - acc: 0.9201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1205 07:36:50.714146 14652 callbacks.py:989] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 293us/sample - loss: 0.3134 - acc: 0.9202 - val_loss: 0.3259 - val_acc: 0.9117\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Objective value missing in metrics reported to the Oracle, expected: ['val_accuracy'], found: dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-21cd41d8ce5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0maveraged_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecution_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         self.oracle.update_trial(\n\u001b[1;32m--> 108\u001b[1;33m             trial.trial_id, metrics=averaged_metrics, step=self._reported_step)\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_configure_tensorboard_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\kerastuner\\engine\\oracle.py\u001b[0m in \u001b[0;36mupdate_trial\u001b[1;34m(self, trial_id, metrics, step)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m    183\u001b[0m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_objective_found\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\kerastuner\\engine\\oracle.py\u001b[0m in \u001b[0;36m_check_objective_found\u001b[1;34m(self, metrics)\u001b[0m\n\u001b[0;32m    349\u001b[0m                 \u001b[1;34m'Objective value missing in metrics reported to the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 'Oracle, expected: {}, found: {}'.format(\n\u001b[1;32m--> 351\u001b[1;33m                     objective_names, metrics.keys()))\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_trial_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Objective value missing in metrics reported to the Oracle, expected: ['val_accuracy'], found: dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
     ]
    }
   ],
   "source": [
    "tuner.search(x, y, epochs=5, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in .\\helloworld</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the best model(s) you can do this simply as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a HyperModel subclass instead of a model-building function\n",
    "This makes it easy to share and reuse hypermodels. A HyperModel subclass only needs to implement a `build(self, hp)` method. \n",
    "\n",
    "Keras Tuner LAO includes pre-made tunable applications - **hyperxception** and **hyperresnet**. These are pretunable hypermodels for computer vision. \n",
    "\n",
    "Below is a sample of how to build your own hypermodel subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import HyperModel\n",
    "\n",
    "\n",
    "class AHyperModelClass(HyperModel):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        #build out a model here\n",
    "        return model\n",
    "\n",
    "\n",
    "hypermodel = AHyperModelClass(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
