{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Layers\n",
    "This notebook explores the concept of shared layers within the Functional API. First let's import Keras and Numpy. We will take the use case of trying to see if two tweets are authored by the same author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 18:56:56.691562 15208 deprecation_wrapper.py:119] From C:\\Users\\jdeha\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 18:56:56.704576 15208 deprecation_wrapper.py:119] From C:\\Users\\jdeha\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "tweet_a = Input(shape=(140, 256))\n",
    "tweet_b = Input(shape=(140, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To share a layer across different inputs, simply instantiate the layer once, then call it on as many inputs as you want. Here we are going to take a LSTM layer and reuse that same instance multiple times. In this way, the weights are effectively being reused. We then join them together using the concatentate function with a final logistic regression layer. These become the outputs with the tweets as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:56:56.713423 15208 deprecation_wrapper.py:119] From C:\\Users\\jdeha\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define LSTM layer\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "#Reuse this layer for both inputs\n",
    "encoded_a = shared_lstm(tweet_a)\n",
    "encoded_b = shared_lstm(tweet_b)\n",
    "\n",
    "# Concatenate these together\n",
    "merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=-1)\n",
    "\n",
    "# And add a logistic regression layer\n",
    "predictions = Dense(1, activation='sigmoid')(merged_vector)\n",
    "\n",
    "#Build the model, linking the tweets to the predictions.\n",
    "model = Model(inputs=[tweet_a, tweet_b], outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this out by generating some random data to simulate the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:57:21.644451 15208 deprecation_wrapper.py:119] From C:\\Users\\jdeha\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1110 18:57:21.662557 15208 deprecation_wrapper.py:119] From C:\\Users\\jdeha\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1110 18:57:21.666557 15208 deprecation.py:323] From C:\\Users\\jdeha\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1110 18:57:23.021037 15208 deprecation_wrapper.py:119] From C:\\Users\\jdeha\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 7s 69ms/step - loss: 0.7604 - acc: 0.5200\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 0.6849 - acc: 0.5700\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6788 - acc: 0.6100\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 4s 38ms/step - loss: 0.6564 - acc: 0.5200\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 0.6274 - acc: 0.7600\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.6201 - acc: 0.6500\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.5845 - acc: 0.8600\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.6046 - acc: 0.6600\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.5392 - acc: 0.8100\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.5516 - acc: 0.7400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbb0803c48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a = np.random.random((100, 140, 256))\n",
    "data_b = np.random.random((100, 140, 256))\n",
    "labels = np.random.randint(2, size=(100, 1))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit([data_a, data_b], labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
